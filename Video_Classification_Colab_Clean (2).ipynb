{"cells":[{"cell_type":"code","execution_count":1,"id":"0a1212a4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0a1212a4","executionInfo":{"status":"ok","timestamp":1746601695740,"user_tz":-330,"elapsed":31077,"user":{"displayName":"Pruthviraj Jagdale","userId":"09243393459988677328"}},"outputId":"fdeac798-1273-40a1-cdb2-9b3f89283f41"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":2,"id":"32b5a441","metadata":{"id":"32b5a441","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1746601789947,"user_tz":-330,"elapsed":86816,"user":{"displayName":"Pruthviraj Jagdale","userId":"09243393459988677328"}},"outputId":"6f1df150-39c9-4f96-86b8-60df67a8dfa6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.30.2)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->timm)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->timm)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->timm)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->timm)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->timm)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->timm)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch->timm)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->timm)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->timm)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->timm)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.2.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.4.26)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m133.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"]}],"source":["!pip install timm\n"]},{"cell_type":"code","execution_count":3,"id":"7c6b8e9d","metadata":{"id":"7c6b8e9d","executionInfo":{"status":"ok","timestamp":1746601808367,"user_tz":-330,"elapsed":11878,"user":{"displayName":"Pruthviraj Jagdale","userId":"09243393459988677328"}}},"outputs":[],"source":["import os\n","import cv2\n","import torch\n","import timm\n","import torch.nn as nn\n","import torch.optim as optim\n","from PIL import Image\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, random_split\n"]},{"cell_type":"code","source":["import os\n","\n","output_real_dir = \"/content/drive/MyDrive/Output/working/frames/real\"\n","output_spoof_dir = \"/content/drive/MyDrive/Output/working/frames/spoof\"\n","\n","os.makedirs(output_real_dir, exist_ok=True)\n","os.makedirs(output_spoof_dir, exist_ok=True)\n"],"metadata":{"id":"F0gNj6iNukRB","executionInfo":{"status":"ok","timestamp":1746601813603,"user_tz":-330,"elapsed":1040,"user":{"displayName":"Pruthviraj Jagdale","userId":"09243393459988677328"}}},"id":"F0gNj6iNukRB","execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"id":"9c905094","metadata":{"id":"9c905094","executionInfo":{"status":"ok","timestamp":1746601830767,"user_tz":-330,"elapsed":33,"user":{"displayName":"Pruthviraj Jagdale","userId":"09243393459988677328"}}},"outputs":[],"source":["real_videos_dir = \"/content/drive/MyDrive/Video classification/Data sets/Real\"\n","spoof_videos_dir = \"/content/drive/MyDrive/Video classification/Data sets/Fake\"\n","\n","output_real_dir = \"/content/drive/MyDrive/Output/working/frames/real\"\n","output_spoof_dir = \"/content/drive/MyDrive/Output/working/frames/spoof\"\n","\n","os.makedirs(output_real_dir, exist_ok=True)\n","os.makedirs(output_spoof_dir, exist_ok=True)\n"]},{"cell_type":"code","source":["import cv2\n","import os\n","\n","def check_video_frames(video_path):\n","    cap = cv2.VideoCapture(video_path)\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    duration = total_frames / fps if fps else 0\n","    print(f\"Video: {video_path}\\nFrames: {total_frames}, FPS: {fps}, Duration: {duration:.2f}s\\n\")\n","    cap.release()\n","\n","# Check all spoof videos\n","for f in os.listdir(spoof_videos_dir):\n","    if f.endswith(('.mp4', '.avi', '.mov')):\n","        check_video_frames(os.path.join(spoof_videos_dir, f))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tmp00GlFx3DY","executionInfo":{"status":"ok","timestamp":1746601834070,"user_tz":-330,"elapsed":1337,"user":{"displayName":"Pruthviraj Jagdale","userId":"09243393459988677328"}},"outputId":"254b6a01-afde-40c0-f7c3-090a6bc671b6"},"id":"tmp00GlFx3DY","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Video: /content/drive/MyDrive/Video classification/Data sets/Fake/Fake3.mp4\n","Frames: 1044, FPS: 24.0, Duration: 43.50s\n","\n"]}]},{"cell_type":"code","execution_count":7,"id":"b24dd693","metadata":{"id":"b24dd693","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746601835684,"user_tz":-330,"elapsed":26,"user":{"displayName":"Pruthviraj Jagdale","userId":"09243393459988677328"}},"outputId":"1d87c28b-8754-4427-da4f-9e2dc9a9ce33"},"outputs":[{"output_type":"stream","name":"stdout","text":["Frame extraction completed.\n"]}],"source":["def extract_frames_from_videos(videos_dir, output_dir, label, max_videos=5):\n","    video_files = [f for f in os.listdir(videos_dir) if f.endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n","    video_files = video_files[:max_videos]\n","\n","    for video_file in video_files:\n","        video_path = os.path.join(videos_dir, video_file)\n","        cap = cv2.VideoCapture(video_path)\n","        frame_count = 0\n","        success, image = cap.read()\n","\n","        while success:\n","            if frame_count % int(cap.get(cv2.CAP_PROP_FPS)) == 0:\n","                frame_filename = f\"{label}_{video_file}_frame{frame_count // int(cap.get(cv2.CAP_PROP_FPS))}.jpg\"\n","                frame_path = os.path.join(output_dir, frame_filename)\n","                cv2.imwrite(frame_path, image)\n","            success, image = cap.read()\n","            frame_count += 1\n","\n","        cap.release()\n","\n","if not os.listdir(output_real_dir):\n","    extract_frames_from_videos(real_videos_dir, output_real_dir, \"real\")\n","if not os.listdir(output_spoof_dir):\n","    extract_frames_from_videos(spoof_videos_dir, output_spoof_dir, \"spoof\")\n","\n","print(\"Frame extraction completed.\")\n"]},{"cell_type":"code","source":["print(\"Real frames:\", len(os.listdir(output_real_dir)))\n","print(\"Spoof frames:\", len(os.listdir(output_spoof_dir)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W1BtBlv8yb2U","executionInfo":{"status":"ok","timestamp":1746601838052,"user_tz":-330,"elapsed":10,"user":{"displayName":"Pruthviraj Jagdale","userId":"09243393459988677328"}},"outputId":"64a71a20-6c14-489d-f393-3cb0f27685fe"},"id":"W1BtBlv8yb2U","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Real frames: 160\n","Spoof frames: 147\n"]}]},{"cell_type":"code","source":["import shutil\n","import os\n","\n","# Create the new path if it doesn't exist\n","if not os.path.exists(\"/content/frames\"):\n","    os.makedirs(\"/content/frames\")\n","\n","# Copy real and spoof folders\n","shutil.copytree(\"/content/drive/MyDrive/Output/working/frames/real\", \"/content/frames/real\", dirs_exist_ok=True)\n","shutil.copytree(\"/content/drive/MyDrive/Output/working/frames/spoof\", \"/content/frames/spoof\", dirs_exist_ok=True)\n","\n","print(\"Copied folders to /content/frames\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kNAMPthfvtTq","executionInfo":{"status":"ok","timestamp":1746601898141,"user_tz":-330,"elapsed":57962,"user":{"displayName":"Pruthviraj Jagdale","userId":"09243393459988677328"}},"outputId":"3864914b-086d-4e1c-cc0f-636e3b7a57f0"},"id":"kNAMPthfvtTq","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Copied folders to /content/frames\n"]}]},{"cell_type":"code","execution_count":10,"id":"5e2e417e","metadata":{"id":"5e2e417e","executionInfo":{"status":"ok","timestamp":1746601898146,"user_tz":-330,"elapsed":7,"user":{"displayName":"Pruthviraj Jagdale","userId":"09243393459988677328"}}},"outputs":[],"source":["# Define transform (you already fixed this)\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","# ✅ NOW define the dataset BEFORE splitting it\n","dataset_dir = \"/content/frames\"\n","dataset = datasets.ImageFolder(root=dataset_dir, transform=transform)\n","\n","# ✅ THEN do the splitting\n","small_dataset, _ = torch.utils.data.random_split(dataset, [200, len(dataset) - 200])\n","train_dataset, val_dataset = torch.utils.data.random_split(small_dataset, [160, 40])\n","\n","\n","train_size = int(0.8 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","\n","train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n"]},{"cell_type":"code","execution_count":11,"id":"83b5e57a","metadata":{"id":"83b5e57a","executionInfo":{"status":"ok","timestamp":1746601905568,"user_tz":-330,"elapsed":2170,"user":{"displayName":"Pruthviraj Jagdale","userId":"09243393459988677328"}},"colab":{"base_uri":"https://localhost:8080/","height":173,"referenced_widgets":["12d06dadf30d49d0a1555e8e4e45853f","edaf9a23a3224dccb15d20e59d4585fe","6d897e62a50f4bda8a3b793ff95e83d7","8354bf4730df434297950f22a9c8be11","c9a8bc207025484089b7c4ff5dd00789","36195df5e7ff429ba7f7bf1f79a78f6c","d99756d0b2464459a64382f6b8cc6b27","0b397de451f2426db40a05dd31232c8b","1df3855f60154f1a9cabaa0e0c6e5dd6","923b044396994dcdbce72388ae4db5be","aee81d338d384250a6fc69272c5894c6"]},"outputId":"502b9b79-d778-4ba9-b08d-cb2f7eae3988"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12d06dadf30d49d0a1555e8e4e45853f"}},"metadata":{}}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = timm.create_model('resnet18', pretrained=True, num_classes=2)\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-4)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.7)\n"]},{"cell_type":"code","execution_count":12,"id":"a22a0387","metadata":{"id":"a22a0387","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746601943367,"user_tz":-330,"elapsed":34326,"user":{"displayName":"Pruthviraj Jagdale","userId":"09243393459988677328"}},"outputId":"21e90886-60f3-470a-96fc-2b20327c7743"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/1], Loss: 0.7002, Training Accuracy: 48.12%\n","Validation Accuracy: 50.00%\n","Best Validation Accuracy: 50.00%\n"]}],"source":["num_epochs = 1\n","best_val_accuracy = 0\n","patience = 5\n","patience_counter = 0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs, 1)\n","        total_train += labels.size(0)\n","        correct_train += (predicted == labels).sum().item()\n","\n","    train_accuracy = 100 * correct_train / total_train\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Training Accuracy: {train_accuracy:.2f}%\")\n","\n","    model.eval()\n","    correct_val = 0\n","    total_val = 0\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)\n","            total_val += labels.size(0)\n","            correct_val += (predicted == labels).sum().item()\n","\n","    val_accuracy = 100 * correct_val / total_val\n","    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n","\n","    if val_accuracy > best_val_accuracy:\n","        best_val_accuracy = val_accuracy\n","        torch.save(model.state_dict(), 'best_vit_model.pth')\n","        patience_counter = 0\n","    else:\n","        patience_counter += 1\n","        if patience_counter >= patience:\n","            print(\"Early stopping due to no improvement.\")\n","            break\n","\n","    scheduler.step()\n","print(f\"Best Validation Accuracy: {best_val_accuracy:.2f}%\")\n"]},{"cell_type":"code","execution_count":13,"id":"4bc2e54e","metadata":{"id":"4bc2e54e","executionInfo":{"status":"ok","timestamp":1746601954421,"user_tz":-330,"elapsed":13,"user":{"displayName":"Pruthviraj Jagdale","userId":"09243393459988677328"}}},"outputs":[],"source":["def predict_video(video_path, model, transform, device):\n","    cap = cv2.VideoCapture(video_path)\n","    real_count = 0\n","    spoof_count = 0\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n","        image = transform(image).unsqueeze(0).to(device)\n","\n","        with torch.no_grad():\n","            outputs = model(image)\n","            _, predicted = torch.max(outputs, 1)\n","\n","        if predicted.item() == 0:\n","            real_count += 1\n","        else:\n","            spoof_count += 1\n","\n","    cap.release()\n","\n","    if real_count > spoof_count:\n","        print(f\"Result: Real video ({real_count} real frames, {spoof_count} spoof frames)\")\n","        return \"Real\"\n","    else:\n","        print(f\"Result: Spoof video ({real_count} real frames, {spoof_count} spoof frames)\")\n","        return \"Spoof\"\n"]},{"cell_type":"code","execution_count":17,"id":"dbed03b3","metadata":{"id":"dbed03b3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746602378267,"user_tz":-330,"elapsed":81453,"user":{"displayName":"Pruthviraj Jagdale","userId":"09243393459988677328"}},"outputId":"98843cfa-bd2b-4188-e46e-edb8d0992fbb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Result: Spoof video (84 real frames, 960 spoof frames)\n"]}],"source":["# Use the correct architecture (ResNet18) that matches your saved model\n","model = timm.create_model('resnet18', pretrained=False, num_classes=2)\n","\n","# Load the weights that were saved from a ResNet18 model\n","model.load_state_dict(torch.load('best_vit_model.pth'))\n","\n","# Move to device and set to eval mode\n","model.to(device)\n","model.eval()\n","\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","video_path = \"/content/drive/MyDrive/Video classification/Data sets/Fake/Fake3.mp4\"\n","result = predict_video(video_path, model, transform, device)\n"]},{"cell_type":"code","source":["import torch\n","\n","# Assuming your model is called MyModel (or adjust as needed)\n","# and you have already trained it\n","\n","# Set to eval mode before saving (recommended)\n","model.eval()\n","\n","# Save only the weights\n","torch.save(model.state_dict(), 'model.pth')\n","\n","print(\"✅ Model saved as model.pth\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJyNlFKK6dm5","executionInfo":{"status":"ok","timestamp":1746037450962,"user_tz":-330,"elapsed":125,"user":{"displayName":"Pruthviraj Jagdale","userId":"09243393459988677328"}},"outputId":"cbee4de4-bc4f-44c0-e1c3-23fb88c7a7c4"},"id":"JJyNlFKK6dm5","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Model saved as model.pth\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"11VyAavmpsiic9a2_sDAaXbipgzvjJ6vz","timestamp":1746039821274}]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"12d06dadf30d49d0a1555e8e4e45853f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_edaf9a23a3224dccb15d20e59d4585fe","IPY_MODEL_6d897e62a50f4bda8a3b793ff95e83d7","IPY_MODEL_8354bf4730df434297950f22a9c8be11"],"layout":"IPY_MODEL_c9a8bc207025484089b7c4ff5dd00789"}},"edaf9a23a3224dccb15d20e59d4585fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36195df5e7ff429ba7f7bf1f79a78f6c","placeholder":"​","style":"IPY_MODEL_d99756d0b2464459a64382f6b8cc6b27","value":"model.safetensors: 100%"}},"6d897e62a50f4bda8a3b793ff95e83d7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b397de451f2426db40a05dd31232c8b","max":46807446,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1df3855f60154f1a9cabaa0e0c6e5dd6","value":46807446}},"8354bf4730df434297950f22a9c8be11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_923b044396994dcdbce72388ae4db5be","placeholder":"​","style":"IPY_MODEL_aee81d338d384250a6fc69272c5894c6","value":" 46.8M/46.8M [00:00&lt;00:00, 176MB/s]"}},"c9a8bc207025484089b7c4ff5dd00789":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36195df5e7ff429ba7f7bf1f79a78f6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d99756d0b2464459a64382f6b8cc6b27":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b397de451f2426db40a05dd31232c8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1df3855f60154f1a9cabaa0e0c6e5dd6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"923b044396994dcdbce72388ae4db5be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aee81d338d384250a6fc69272c5894c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}